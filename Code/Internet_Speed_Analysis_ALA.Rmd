---
title: "Download Speeds by State"
author: "Bree Norlander"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: html_notebook
---

```{r}
library(RSocrata)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(aws.s3)
```

```{r}
erate_imls <- s3read_using(FUN = read.csv, object = "data/AVI8-SVP9_Commitments/Libraries_Funded_Committed_AVI8-SVP9_with_FSCS_Matches.csv", bucket = "erate-data")

# Read in IMLS PLS dataset stored in S3
full_imls <- s3read_using(FUN = read.csv, object = "data/IMLS_PLS/2014-2020_OUTLETs_and_AEs_Merged.csv", bucket = "erate-data")

# Read in IMLS PLS AE 2020 dataset stored in S3
imls_ae_2020 <- s3read_using(FUN = read.csv, object = "data/IMLS_PLS/2020_IMLS_PLS_AE.csv", bucket = "erate-data")

bucket <- get_bucket_df("erate-data")
LastModified <- as.Date(bucket$LastModified[bucket$Key == "data/AVI8-SVP9_Commitments/Libraries_Funded_Committed_AVI8-SVP9_with_FSCS_Matches.csv"])

# Read in purpose dataset from 
purpose <- read.socrata(
  "https://opendata.usac.org/resource/hbj5-2bpj.json?funding_year=2022",
  app_token = Sys.getenv("USAC_Socrata")
)
```

```{r}
# Add in LOCALE Descriptions to full_imls
full_imls <- full_imls %>% 
  mutate(
    LOCALE_ADD_DESCR = case_when(
      LOCALE_ADD == 11 ~ "City Large",
      LOCALE_ADD == 12 ~ "City Midsize",
      LOCALE_ADD == 13 ~ "City Small",
      LOCALE_ADD == 21 ~ "Suburban Large",
      LOCALE_ADD == 22 ~ "Suburban Midsize",
      LOCALE_ADD == 23 ~ "Suburban Small",
      LOCALE_ADD == 31 ~ "Town Fringe",
      LOCALE_ADD == 32 ~ "Town Distant",
      LOCALE_ADD == 33 ~ "Town Remote",
      LOCALE_ADD == 41 ~ "Rural Fringe",
      LOCALE_ADD == 42 ~ "Rural Distant",
      LOCALE_ADD == 43 ~ "Rural Remote",
      LOCALE == 11 ~ "City Large",
      LOCALE == 12 ~ "City Midsize",
      LOCALE == 13 ~ "City Small",
      LOCALE == 21 ~ "Suburban Large",
      LOCALE == 22 ~ "Suburban Midsize",
      LOCALE == 23 ~ "Suburban Small",
      LOCALE == 31 ~ "Town Fringe",
      LOCALE == 32 ~ "Town Distant",
      LOCALE == 33 ~ "Town Remote",
      LOCALE == 41 ~ "Rural Fringe",
      LOCALE == 42 ~ "Rural Distant",
      LOCALE == 43 ~ "Rural Remote"
    )) %>% 
  # separate to create high-level category
  # https://stackoverflow.com/a/53701998
  separate(LOCALE_ADD_DESCR, 
        into = c("LOCALE_TOP_LEVEL_DESCR", NA),
        sep = " ")
```

```{r}
# Create a specific filtered dataset for this analysis
erate_2022 <- erate_imls %>% 
  filter(chosen_category_of_service == "Category1",
         form_471_function_name != "Miscellaneous",
         form_471_product_name != "Data plan for portable device",
         funding_year == 2022,
         !is.na(form_471_download_speed_unit_name),
         !is.na(FSCSKEY),
         MOST_RECENT_PLS == 2020) %>% 
  left_join((purpose %>% 
               select(application_number, form_471_line_item_number, form_471_purpose_name, form_version, connection_directly_school, connection_supports_service) %>% 
               filter(form_version == "Current") %>% 
               mutate(application_number = as.numeric(application_number),
                      form_471_line_item_number = as.numeric(form_471_line_item_number))
             ), 
            by=c("application_number", "form_471_line_item_number")) 
```

```{r}
# Add normalized columns of upload and download speed requested to the dataset
# Add FCC tiers (plus Chris J's served vs. gigabit) based on upload and download speeds
erate_2022 <- erate_2022 %>%
  # Normalize the download and upload speeds to Megabits per second
  mutate(download_speed_mbps = case_when(
    form_471_download_speed_unit_name == "Mbps" ~ download_speed,
    form_471_download_speed_unit_name == "Gbps" ~ download_speed * 1000
  )) %>%
  mutate(upload_speed_mbps = case_when(
    form_471_upload_speed_unit_name == "Mbps" ~ download_speed,
    form_471_upload_speed_unit_name == "Gbps" ~ download_speed * 1000
  )) %>% 
  mutate(speed_tier = case_when(
    download_speed_mbps < 25  ~ "unserved",
    download_speed_mbps >= 25 & download_speed_mbps < 100  ~ "underserved",
    download_speed_mbps >= 100 & download_speed_mbps < 1000  ~ "served_not_gigabit",
    download_speed_mbps >= 1000 & upload_speed_mbps < 1000  ~ "served_not_gigabit",
    download_speed_mbps >= 1000 & upload_speed_mbps >= 1000  ~ "gigabit"
  )) %>% 
  mutate(gigabit_binary = if_else(download_speed_mbps >= 1000 & upload_speed_mbps >= 1000, "gigabit", "not_gigabit"))
```

```{r}
# Add in LSA population
erate_2022 <- erate_2022 %>% 
  left_join((imls_ae_2020 %>% 
               filter(!is.na(POPU_LSA)) %>% 
               distinct(FSCSKEY, POPU_LSA)),
            by = "FSCSKEY")
```

```{r}
# Add categorical variable indicating whether the request meets the 
# FCC/ALA speed benchmark for fixed broadband
# https://www.fcc.gov/general/summary-e-rate-modernization-order
erate_2022 <- erate_2022 %>%
  mutate(speed_benchmark = case_when(
    POPU_LSA == -3 ~ "computation error LSA",
    POPU_LSA == -9 ~ "computation error LSA",
    is.na(POPU_LSA) ~ "computation error LSA",
    download_speed_mbps >= 100 & POPU_LSA <= 50000 ~ "benchmark met",
    download_speed_mbps >= 1000 & POPU_LSA > 50000 ~ "benchmark met",
    download_speed_mbps < 100 ~ "benchmark not met",
    download_speed_mbps < 1000 & POPU_LSA > 50000 ~ "benchmark not met"
  ))
```

```{r}
# Add categorical variable indicating whether LSA population greater than or less than 50,000
erate_2022 <- erate_2022 %>%
  mutate(pop_category = case_when(
    POPU_LSA == -3 ~ "closedAE",
    POPU_LSA == -9 ~ "suppressed",
    is.na(POPU_LSA) ~ "unknown",
    POPU_LSA <= 50000 ~ "under50",
    POPU_LSA > 50000 ~ "over50"
  ))
```


```{r}
# write out a csv of select columns
write.csv((erate_2022 %>% select(ros_entity_number:ros_entity_type, 
                                 ros_subtype, 
                                 ros_physical_address:ros_physical_zipcode,
                                 ros_urban_rural_status,
                                 billed_entity_number:organization_entity_type_name,
                                 funding_year:form_471_frn_status_name,
                                 spin_name:post_discount_applicant_share,
                                 tribal_type,
                                 cat1_discount_by_ros_estimated:form_version,
                                 ros_longitude,
                                 ros_latitude,
                                 POPU_LSA,
                                 download_speed_mbps,
                                 upload_speed_mbps,
                                 speed_tier,
                                 speed_benchmark)),
          "~/Documents/GitHub/E-Rate/Data/Internet_Speed_Applications_2022.csv")
```

```{r}
# How many distinct ros_entity_numbers in our filtered erate dataset?
erate_2022 %>% 
  distinct(ros_entity_number) %>% 
  nrow()
```

```{r}
# Find out how many unique libs applied for erate in 2022
erate_imls %>% 
  filter(funding_year == 2022) %>%  
  distinct(ros_entity_number) %>% 
  nrow()
```

```{r}
# Find out how many unique libs in whole dataset have IMLS codes
erate_imls %>% 
  filter(funding_year == 2022,
         !is.na(FSCSKEY)) %>% 
  distinct(ros_entity_number) %>% 
  nrow()
```

```{r}
# Find out how many unique libs in whole dataset have IMLS codes from 2020 PLS
erate_imls %>% 
  filter(funding_year == 2022,
         !is.na(FSCSKEY), 
         MOST_RECENT_PLS == 2020) %>% 
  distinct(ros_entity_number) %>% 
  nrow()
```

```{r}
# How many total unique imls entities in 2020
full_imls %>% 
  filter(PLS_YEAR == 2020) %>% 
  distinct(FSCSKEY, FSCS_SEQ) %>% 
  nrow()
```

```{r}
# count libs by function
erate_2022 %>%
  group_by(form_471_function_name) %>% 
  summarize(num_libs = n_distinct(ros_entity_number)) %>% 
  mutate(pct = round(num_libs/sum(num_libs)*100, 1))
```

```{r}
# Count libs by function and purpose
erate_2022 %>%
  group_by(form_471_function_name, form_471_purpose_name) %>% 
  summarize(num_libs = n_distinct(ros_entity_number)) %>% 
  pivot_wider(names_from = form_471_function_name, values_from = c('num_libs')) 
```

```{r}
# Count libs by function and urban/rural
erate_2022 %>%
  group_by(form_471_function_name, ros_urban_rural_status) %>% 
  summarize(num_libs = n_distinct(ros_entity_number)) %>% 
  ungroup() %>% 
  mutate(pct = round(num_libs/sum(num_libs)*100, 1)) 
```

```{r}
# Count libs by function and population category
erate_2022 %>%
  group_by(form_471_function_name, pop_category) %>% 
  summarize(num_libs = n_distinct(ros_entity_number)) %>%
  ungroup() %>% 
  mutate(pct = round(num_libs/sum(num_libs)*100, 1)) 
```

```{r}
erate_2022 %>%
  group_by(speed_tier) %>%
  summarize(count_distinct = n_distinct(ros_entity_number))
```

```{r}
erate_2022 %>% 
  summarize(num_libs = n_distinct(ros_entity_number))
```

```{r}
erate_2022 %>% 
  filter(!is.na(FSCSKEY) & !is.na(FSCS_SEQ)) %>% 
  summarize(num_libs = n_distinct(ros_entity_number)) 
```

```{r}
erate_2022 %>%
  group_by(speed_tier, form_471_function_name, form_471_product_name) %>%
  summarize(count_distinct = n_distinct(ros_entity_number)) %>% 
  pivot_wider(names_from = speed_tier, values_from = count_distinct) %>% 
  arrange(form_471_function_name, form_471_product_name)
```

```{r}
# could you make a salsa file for each of the 6 connection purposes? 

purposes <- erate_2022 %>% 
  distinct(form_471_purpose_name) %>% 
  pull()

for (x in purposes) {
  erate_2022 %>% 
    filter(form_471_purpose_name == x) %>% 
    write.csv(paste0("~/Documents/GitHub/E-Rate/Data/", str_trunc(str_replace_all(string=x, pattern=" ", repl=""), 30, "right", ellipsis = ""), ".csv"))
}

```


# IA Only

```{r}
# Create a dataset that only includes the two purposes that begin with the words Internet access
ia_only <- erate_2022 %>% 
  filter(grepl('^Internet access', form_471_purpose_name)) %>% 
  add_count(ros_entity_number, name = "how_many_rows_per_lib")
```

```{r}
# How many distinct ros_entity_numbers in ia dataset?
ia_only %>% distinct(ros_entity_number) %>% nrow()
```

```{r}
# Count libs by function
ia_only %>%
  group_by(form_471_function_name) %>% 
  summarize(num_libs = n_distinct(ros_entity_number)) %>% 
  mutate(pct = round(num_libs/sum(num_libs)*100, 1))
```

```{r}
# Count libs by function and product
ia_only %>%
  group_by(form_471_function_name, form_471_product_name) %>% 
  summarize(num_libs = n_distinct(ros_entity_number)) %>% 
  ungroup() %>% 
  mutate(pct = round(num_libs/sum(num_libs)*100, 1))
```

```{r}
# Count libs by gigabit binary
ia_only %>%
  group_by(gigabit_binary) %>% 
  summarize(num_libs = n_distinct(ros_entity_number)) %>% 
  mutate(pct = round(num_libs/sum(num_libs)*100, 1))
```

